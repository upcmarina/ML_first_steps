---
title: "Analysis of Prostate Cancer data"
author: "Marina Vallejo Vallés (marina.vallejo01@estudiant.upf.edu)"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"    
output:
  html_document:
    toc: yes
    fig_caption: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
# Set a seed in order to be able to replicate the results, as we are working with random numbers
set.seed(123456)
```

```{r, include=FALSE, warning=FALSE}
library(tidymodels)
library(ISLR)
library(corrplot)
library(randomForest)
library(caret)
library(gridExtra)
library(class)
library(gmodels)
library(C50)
library(nnet)
library(NeuralNetTools)
library(pROC)
```

Data from Stamey et al. 1989.

During this report we will **train a model that predicts log of prostate-specific antigen (lpsa).** 

**Brief introduction.**

In the publication, they examined the correlation between the level of prostate-specific antigen (PSA) and a number of clinical measures in men who were about to receive a radical prostatectomy. PSA is a protein that is produced by the prostate gland. The higher a man’s PSA level, the more likely it is that he has prostate cancer.

The variables are log cancer volume (lcavol), log prostate weight (lweight), age, log of the amount of benign prostatic hyperplasia (lbph), seminal vesicle invasion (svi), log of capsular penetration (lcp), Gleason score (gleason), and percent of Gleason scores 4 or 5 (pgg45).

Prostate data info: 

* Predictors (columns 1--8)
1. lcavol
2. lweight
3. age
4. lbph
5. svi
6. lcp
7. gleason
8. pgg45

* Outcome (column 9): 
9. lpsa

# EDA

**Work with the data set.**

```{r}
# Load data:
prostate_dataset <- read.csv("prostate_cancer_data.txt", sep="\t")

# Summary of the data:
summary(prostate_dataset)
```

Pearson correlation:
```{r}
prostate_correlations <- cor(prostate_dataset,method="pearson")

# Generate correlation plot:
corrplot(prostate_correlations, hclust.method = "ward",method = "square", 
          order = "FPC", type = "full", tl.col = "darkslategray")
```

In order to select the variables for the model to predict **lpsa**, we check the Pearson correlation values:
```{r}
prostate_correlations
```
For our linear regression model, as the highest correlation value is for **lpsa-lcavol : 0.73** (ignore X as it is an identifier), a first approach could be to have **lpsa** as response and **lcavol** as the predictor. It will be a simple linear regression.

# MODEL BUILDING

First of all we have to split the data. 3/4 data will be retained for modeling and variable **lpsa** will be used to stratify the samples:
```{r}
# Generate the split object:
prostate_split <- data_split <- initial_split(prostate_dataset, prop = 3/4, strata = lpsa)

# Build the training prostate dataset (with 3/4 of the data)
prostate_training <- prostate_split %>% training()

# Build the testing prostate dataset:
prostate_test <- prostate_split %>% testing()
```


## Simple linear regression

* Response : lpsa

* Predictor: lcavol

Now generate the model (linear regression):
```{r}
simple_lm <- linear_reg() %>% set_mode("regression") %>% set_engine("lm")
# set_mode is redundant, as it can only be regression, but we keep it in order to be verbose

# Check:
simple_lm
```

Fit model with our training data previously generated, having **lcavol** as predictor and **lpsa** as response:
```{r}
fit_simple_lm <- simple_lm %>% fit(lpsa ~ lcavol, data = prostate_training)

# Check summary
fit_simple_lm %>% pluck("fit") %>%summary()
```

Check the parameter estimates of the fit object:
```{r}
tidy(fit_simple_lm)
```

Extract the model statistics:
```{r}
glance(fit_simple_lm)
```

Obtain plots:
```{r}
par(mfrow=c(2,2))

plot(fit_simple_lm$fit, pch = 21, col = '#990066')
```

The **Residuals vs. Fitted** plot is used to detect non-linearity of data, as well as unequal error variances, and outliers. In our plot the linearity seems to hold reasonably well. The red line is close to the dashed grey line. Points 69 and 96 could be considered as outliers, as they have large residual values. And finally we can confirm heteroskedasticity, when we move to the right (x-axis), the spread seems to increase.

The **Quantile-Quantile (QQ)** plot is a visual way to check if a variable is normal. It compares the quantiles of our data against the quantiles of another distribution, the desired one (in our case the normal distribution). As we can see our data mostly fall in the dashed line, so we can assume it has a normal distribution.


Prediction, with test dataset (1/4 of the original data).
```{r}
results_prostate_test <- predict(fit_simple_lm, new_data = prostate_test) %>% bind_cols(prostate_test)
```

Root Mean Square Error (rmse):
```{r}
# .pred is our predictor, previously generated by the predict function
rmse(results_prostate_test, truth = lpsa, estimate = .pred)
```

The Root Mean Square Error (rmse) allows us to measure the error of a model when predicting quantitative data. A low value of rmse indicates that the model is able to properly fit a data set. For our **linear regression** model it is equal to 0.8, we will check later if it is improved with the **multiple regression** model.

Square Error (rsq):
```{r}
rsq_model <- rsq(results_prostate_test, truth = lpsa, estimate = .pred)
rsq_model
```

Plots:
```{r}
ggplot(data = results_prostate_test,
       mapping = aes(x = .pred, y = lpsa)) +
       geom_point( size = 2.5,colour="mediumorchid1",pch=19,alpha = 0.8)+
       geom_abline(intercept = 0, slope = 1, color = 'mediumorchid4') +
       labs(title = 'Simple Linear Regression Results : lcavol predicting lpsa',
       x = 'Predicted lpsa',y = 'Actual lpsa')+
       theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = "none",
       panel.background = element_blank(), axis.line = element_line(colour = "black"),
       plot.title = element_text(hjust = 0.5))+
       geom_text(x=4.2, y=3.8, label=format(round(rsq_model$.estimate, 4)), color = 'mediumorchid4')
```

Here we have the visual representation of the results of our simple linear regression model, with an R-squared equal to 0.55

## Multiple linear regression

As the previously generated model is not optimal, we are going to make a second approach. In order to improve the model here we will include extra predictor variables and perform a multiple linear regression. 

The predictor variables included in this new model will be the ones that had a correlation value greater than 0.5 in the first part of the report.

* Response : lpsa

* Predictors: lcavol, svi, lcp

```{r}
# We can reuse simple_lm created before
fit_multiple_lm <- simple_lm %>% fit(lpsa ~ lcavol + svi + lcp, data = prostate_training)
# Check summary
fit_multiple_lm %>% pluck("fit") %>%summary()
```

Check the parameter estimates of the fit object:
```{r}
tidy(fit_multiple_lm)
```

Extract the model statistics:
```{r}
glance(fit_multiple_lm)
```

Obtain plots:
```{r}
par(mfrow=c(2,2))

plot(fit_multiple_lm$fit, pch = 21, col = '#990066')
```

In our **Residuals vs. Fitted** plot the linearity again seems to hold well, as the red line is close to the dashed grey line. Points 69 and 96 again can be considered as outliers, including this time point 18, as they have large residual values. In this case I wouldn't say that we have heteroskedasticity, the spreed seem to be equal on both sides.

In the **Quantile-Quantile (QQ)** data again, mostly fall in the dashed line, so we can assume it has a normal distribution. 

Prediction, with test data set (1/4 of the original data).
```{r}
results_prostate_test2 <- predict(fit_multiple_lm, new_data = prostate_test) %>% bind_cols(prostate_test)
```

Root Mean Square Error (rmse):
```{r}
rmse(results_prostate_test2, truth = lpsa, estimate = .pred)
# .pred is our predictor, previously generated by the predict function
```

Here we have improved the rmse compared to the **linear regression** rmse, we have a lower value.

Square Error (rsq):
```{r}
rsq_model2 <- rsq(results_prostate_test2, truth = lpsa, estimate = .pred)
rsq_model2
```
```{r}
ggplot(data = results_prostate_test2,
       mapping = aes(x = .pred, y = lpsa)) +
       geom_point( size = 2.5,colour="mediumorchid1",pch=19,alpha = 0.8)+
       geom_abline(intercept = 0, slope = 1, color = 'mediumorchid4') +
       labs(title = 'Multiple Linear Regression Results : lcavol/svi/lcp predicting lpsa',
       x = 'Predicted lpsa',y = 'Actual lpsa')+
       theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = "none",
       panel.background = element_blank(), axis.line = element_line(colour = "black"),
       plot.title = element_text(hjust = 0.5))+
       geom_text(x=4.2, y=3.9, label=format(round(rsq_model2$.estimate, 4)), color = 'mediumorchid4')
```

Here we have the visual representation of the results of our multiple linear regression model, with an R-squared equal to 0.63

**Model comparison. Discussion.**

Overall, we have seen that the performance of the **multiple linear regression** model was better than the **simple linear regression** model. 

For the **multiple linear regression** model we had a lower rmse value indicating that the model is able to properly fit a data set.

It also had a greater R-squared, indicating a better adjustment of the predicted data to the linear function.

Further models should be explored in order to improve the prediction of `log of prostate-specific antigen (lpsa)` , maybe using a different subset of predictors and increasing the number of predictor variables. But always considering the risk of overfitting the model and its negative effects.
